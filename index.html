<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <canvas id="surface" width="512" height="512"></canvas>
    <!-- using type = "module" attribute to be able to use top-level awaits -->
    <script type="module">
        const GRID_SIZE = 32;//a constant to keep track of the grid size
        const canvas = document.getElementById("surface");
        //check if the user's browser can use WebGPU.
        if(!navigator.gpu){
            throw new Error("Your browser doesn't support WebGPU.");
        }
        //if WebGPU is supported start by requesting a GPUAdapter.
        //this GPUAdapter is a representation of a specific part of GPU hardware in your computer.
        const adapter = await navigator.gpu.requestAdapter();//this returns a promise, so we await it
        if(!adapter){
            throw new Error("No GPU adapter found.");
        }
        //if you successfully got an adapter you need to request a GPU device
        //the device is the interface through which most of the interaction with the GPU happens.
        const device = await adapter.requestDevice();
        if(!device){
            throw new Error("No GPU device found."); } //now that you have a GPU device you need to configure the canvas so that the device can draw on it //the canvas context needs to be associated with the device using the .configure() method from context object
        const context = canvas.getContext("webgpu");
        const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
        //GPUs work in terms of triangles so to represent a square with the vertices 
        /*[            
            //X, Y
            -0.8,-0.8,
            0.8,-0.8,
            0.8,0.8,
            -0.8,0.8
        ]*/
        //You need to provide the vertices in groups of three, which describe the three vertices of each triangle
        /*[            
            //V1,      V2,      V3
            //X1 Y1    X2  Y2   X3   Y3
            -0.8,-0.8, 0.8,0.8, -0.8,0.8//triangle 1
            -0.8,-0.8, 0.8,-0.8, 0.8,-0.8//triangle 2
        ]*/
        const vertices = new Float32Array([
            //V1,      V2,      V3
            //X1 Y1    X2  Y2   X3   Y3
            -0.8,-0.8, 0.8,-0.8, 0.8,0.8,//triangle 1
            -0.8,-0.8, 0.8,0.8, -0.8,0.8//triangle 2
        ]);
        //GPU can't draw vertices with data from Javascript arrays, for any data to be used by GPU
        //while it draws, it needs to be accessed from the GPU rendering optimized memory
        //the GPU API for doing this is the GPUBuffer
        const vertexBuffer = device.createBuffer({
            label: "cell vertices",//label for the buffer, labels are used in WebGPU error messages
            size: vertices.byteLength,//give the size for the buffer in bytes, size for float32 == 4 bytes, # of float32 in vertices array == 12, 12x4 == 48 bytes
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,//specify the usage of the buffer, making buffer usable for vertex data and enable copying data into it
        });
        //you Can't resize a buffer after it's been created nor can you change usage flags, only able to change its memory contents
        //copy the vertices into the newly created buffer
        device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/0, vertices)
        //vertices data is now copied into the buffer, but for GPU is just random blob of bytes
        //define vertex data structure with a GPUVertexBufferLayout dictionary
        const vertexBufferLayout = {
            arrayStride: 8,//this is the number of bytes GPU needs to skip forward in buffer when looking for next vertex, two (float32 = 4 bytes) per vertex coordinate (x,y) == 8 bytes to skip
            attributes: [{
                format: "float32x2",//each vertice is made up of 2 float32, if they were made up of 4 float32 you would use "float32x4"
                offset: 0,//how many bytes into the buffer this particular attribute starts? it's the first attribute so from the 0th byte
                shaderLocation: 0,//This is an arbitrary number between 0 and 15 and must be unique for every attribute that you define
            }],
        };

        //creating uniforms array
        const uniforms = new Float32Array([GRID_SIZE, GRID_SIZE]);
        //creating uniform buffer to provide the grid size to the shader as uniforms
        //normally when you pass a vertex buffer to a vertex shader every invocation of the vertex shader takes a different value from the vertex buffer
        //this is different from uniforms which is a value from a buffer that is the same for every invocation of the vertex shader
        const uniformBuffer = device.createBuffer({
            label: "grid uniforms",
            size: uniforms.byteLength,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
        });
        device.queue.writeBuffer(uniformBuffer, 0, uniforms);

        const cellShaderModule = device.createShaderModule({
            label: "cell shader",
            code: `
            struct VertexInput {
                @location(0) pos: vec2f,//@location(0) because only one attribute in the vertexBufferLayout?
                @builtin(instance_index) instance: u32,
            };
            struct VertexOutput{
                @builtin(position) pos: vec4f,
                @location(0) cell: vec2f,//@location(0) because only one color attachment in the render pass?
            };
            //defining an uniform in the shader module called 'grid'
            @group(0) @binding(0) var<uniform> grid: vec2f;//this grid works as a global definition just as the VertexInput and VertexOutput structs
            @vertex
            fn vertexMain(input: VertexInput) -> VertexOutput{
                //pos(x,y) and grid(x,y) are 2D vectors WGSL performs an element wise division (pos.x/grid.x, pos.y/grid.y)
                //the division between pos and grid means that whatever n is GRID_SIZE will be the number of rows and cols in grid
                let cell = vec2f(floor(f32(input.instance) / grid.x),(f32(input.instance) % grid.y));//map 0-15,0-15 -> 0-3,0-3 | /grid.x floor division for x, %grid.y modulo for y 
                let offset = cell * (2 / grid);//this offset (a full grid) is to be used once the pos has been scaled and translated and maps user defined coordinates to grid squares in clip space
                let new_pos = (input.pos / grid) + (1 / grid);//this takes the position of the origin from which vertices are drawn and we offset them by half grid cell in (x,y)
                let new_pos_x = new_pos.x - 1;//this takes the origin with half grid offset and moves it in x to the start of clip space
                let new_pos_y = new_pos.y - 1;//this takes the origin with half grid offset and moves it in y to the start of clip space
                var output: VertexOutput;
                output.pos = vec4f(new_pos_x + offset.x, new_pos_y + offset.y, 0, 1);
                output.cell = cell;
                return output;//(x,y,z,w)
            }
            @fragment
            fn fragmentMain(input: VertexOutput) -> @location(0) vec4f{
                return vec4f(input.cell.x/grid.x, input.cell.y/grid.y, 1 - (input.cell.x/grid.x), 1);//(red, green, blue, alpha);
            }
            `,
        });

        //a shader module can't be used for rendering on it's own
        //you have to use it as part of a GPURenderPipeline,
        const renderPipeline = device.createRenderPipeline({
            label: "cell pipeline",
            layout: "auto",//describes what types of inputs (other than vertex buffers) the pipeline needs
            vertex: {
                module: cellShaderModule,
                entryPoint: "vertexMain",
                buffers: [vertexBufferLayout],
            },
            fragment: {
                module: cellShaderModule,
                entryPoint: "fragmentMain",
                targets: [{
                    format: canvasFormat
                }]
            }
        });

        //the uniform declared in the shader code won't bind itself to the uniform buffer created
        //to accomplish this you need to create and set a bind group, which is a collection of resources that
        //you want to make accessible to your shader at the same time
        const bindGroup = device.createBindGroup({
            label: "cell renderer bind group",
            layout: renderPipeline.getBindGroupLayout(0),
            entries: [{//each entry is a dictionary with at least the following properties
                binding: 0,//binding corresponds with the @binding() added to the shader code, in this case @binding(0)
                resource: {buffer: uniformBuffer},//the actual resource that you want to expose to the variable at the specified binding index
            }],
        });
        //you can't change the resources that a bind group points to after it's been created, but you can change the contents of those resources
        //you can for example change the uniform buffer to contain a new grid size which is reflected in future draw calls using this bind group

        context.configure({
            device,
            format: canvasFormat,//format refers to the texture format that the context should use
        });
        //clearing the canvas with a color
        //to do anything with the GPU you need to provide commands to the GPU telling it what to do.
        //to create commands create a GPUCommandEncoder through the GPU device.
        const encoder = device.createCommandEncoder();

        //Render passes are when all drawing operations in WebGPU happen
        const pass = encoder.beginRenderPass({
            colorAttachments: [{
                view: context.getCurrentTexture().createView(),//texture
                clearValue: {r:0,g:0,b:0,a:0.5},//sets the color to clear the canvas with, (red, green, blue, alpha/opacity) ranges 0-1
                loadOp: "clear",//indicate that you want the  texture to be cleared when the render pass starts
                storeOp: "store",//indicate that you want to save into the texture the results of any drawing done during the render pass
            }]
        });
        pass.setPipeline(renderPipeline);
        pass.setVertexBuffer(0, vertexBuffer);
        pass.setBindGroup(0, bindGroup);//the 0 passed as the first argument refers to @group(0) in the shader code
        pass.draw(vertices.length / 2, GRID_SIZE*GRID_SIZE);
        pass.end();
        //calling beginRenderPass() encoder method and end() render method does not cause GPU to do anything
        //they're just recording the commands for the GPU to do later.
        //create a command buffer to deliver the commands to the GPU to perform.
        const commandBuffer = encoder.finish();
        //submit the command buffer to the GPU using the queue of GPUDevice
        device.queue.submit([commandBuffer]);//it is passed as an array of command buffers, this time it's only a command to clear the screen with a color
        //once you submit a command buffer, it cannot be used again, so there's no need to hold on to it. 

        //NOTES
        /*
        You don't have to repeat the vertex data in order to make triangles. 
        Using something called Index Buffers, you can feed a separate list of values to the GPU 
        that tells it what vertices to connect together into triangles so that they don't need to be duplicated. 


        Shaders are small programs that you write and that execute on your GPU. Each shader operates on a different stage of the data: 
        Vertex processing, Fragment processing, or general Compute. Because they're on the GPU, they are structured more rigidly than your average JavaScript.
        But that structure allows them to execute very fast and, crucially, in parallel!


        Shaders in WebGPU are written in a shading language called WGSL (WebGPU Shading Language). 
        WGSL is, syntactically, a bit like Rust, with features aimed at making common types of GPU work (like vector and matrix math) easier and faster.
        WebGPU Shading Language: https://gpuweb.github.io/gpuweb/wgsl/
        */
    </script>
</body>
</html>